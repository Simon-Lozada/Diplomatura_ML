{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3-mJXwPodQgZ",
    "outputId": "a5ef8cef-0cf8-45e0-c325-632bd510ad58"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "# https://chatbotslife.com/text-classification-using-algorithms-e4d50dcba45#.ig9im3fie\n",
    "\n",
    "''' Hoy vamos a aproximarnos a cómo funcionan los chat-bots, x ejemplo Boti :)\n",
    "Una de las partes más importantes es el 'CLASIFICADOR DE TEXTO', es decir, a\n",
    "qué categoría asigna la frase que recibe: es un saludo, es un pedido???\n",
    "Recordemos que la HIPÓTESIS FUERTE DE BAYES NAIVE ES QUE LAS CARACTERÍSTICAS\n",
    "A CLASIFICAR SON INDEPENDIENTES ENTRE SÍ.\n",
    "Se cumple ésto en las palabras de una frase? en general podemos decir que sí,\n",
    "ya que NO estamos tratando de ENTENDER la frase, sino de asignarla a una\n",
    "categoría. Es 'ingenuo' pero cierto.\n",
    "\n",
    "Si yo digo: 'LA OVEJA SALTÓ LA CERCA ANOCHE', excepto los artículos femeninos\n",
    " LA,el resto de las palabras son independientes entre sí, ya que sólo están\n",
    "conectadas por el SENTIDO de la frase y su CONTEXTO.\n",
    "Si quisiera asignar la frase a una categoría, puedo decir que es un saludo? NO,\n",
    "no hay ni HOLA, ni CÓMO ESTÁN? ni ninguna palabra que podamos relacionar con la\n",
    "categoría 'saludos'.\n",
    "Puedo decir que les estoy contando algo? Quizá la podemos clasificar como\n",
    "'relatos de ovejas' si entrenamos adecuadamente al clasificador. SIEMPRE, LO\n",
    "MÁS IMPORTANTE ES ENTRENAR APROPIADAMENTE AL CLASIFICADOR!!!!\n",
    "\n",
    "Así que podemos suponer que estamos en la hipótesis de Bayes Ingenuo.\n",
    "\n",
    "A estos efectos, en NLP (Procesamiento del Lenguaje Natural) a una oración\n",
    "se la denomina 'Bolsa de palabras' (o 'bag of words').\n",
    "\n",
    "PASOS A RECORRER\n",
    "\n",
    "1. Importar librerías que necesitamos\n",
    "    Usaremos NLTK para 2 procesos importantes:\n",
    "        * TOKENIZAR: 'romper' la oración en cadenas de palabras separadas\n",
    "                    ()\n",
    "        * STEMMING: encuentra la 'raíz' de la palabra: 'corriendo' tiene como\n",
    "                    raíz 'corr', como 'correré' o 'corrí' ('trocea' palabras)\n",
    "                    Usaremos Lancaster Stemmer (buenas características para eng)\n",
    "\n",
    "2. Proveer data de entrenamiento: definimos 'clases' para el entrenamiento\n",
    "\n",
    "3. Organizar nuestros datos\n",
    "\n",
    "4. Iterar: modelo + entrenamiento\n",
    "\n",
    "5. Clasificar\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# usamos 'natural language toolkit'  https://www.nltk.org/\n",
    "import nltk\n",
    "nltk.download('punkt')  # esta línea depende de cómo tengo mi OS, y puede cambiar\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "# 'troceador' de palabras\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "foaQ-Z1LdXTl",
    "outputId": "8b702df6-d066-4708-99ad-49a312e41478"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 oraciones para entrenamiento\n"
     ]
    }
   ],
   "source": [
    "# 3 clases de datos para entrenamiento\n",
    "training_data = []\n",
    "training_data.append({\"clase\":\"saludo\", \"oración\":\"how are you?\"})\n",
    "training_data.append({\"clase\":\"saludo\", \"oración\":\"how is your day?\"})\n",
    "training_data.append({\"clase\":\"saludo\", \"oración\":\"good day\"})\n",
    "training_data.append({\"clase\":\"saludo\", \"oración\":\"how is it going today?\"})\n",
    "\n",
    "training_data.append({\"clase\":\"despedida\", \"oración\":\"have a nice day\"})\n",
    "training_data.append({\"clase\":\"despedida\", \"oración\":\"see you later\"})\n",
    "training_data.append({\"clase\":\"despedida\", \"oración\":\"have a good night\"})\n",
    "training_data.append({\"clase\":\"despedida\", \"oración\":\"talk to you soon\"})\n",
    "\n",
    "training_data.append({\"clase\":\"sandwich\", \"oración\":\"make me a sandwich\"})\n",
    "training_data.append({\"clase\":\"sandwich\", \"oración\":\"can you make a sandwich?\"})\n",
    "training_data.append({\"clase\":\"sandwich\", \"oración\":\"having a sandwich today?\"})\n",
    "training_data.append({\"clase\":\"sandwich\", \"oración\":\"what's for lunch?\"})\n",
    "\n",
    "print (f\"{len(training_data)} oraciones para entrenamiento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGUfVC2Ada_A",
    "outputId": "6a6d9dbd-feb9-46bf-8731-2b5c0274355b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus de palabras y cantidad: {'how': 3, 'ar': 1, 'you': 4, 'is': 2, 'yo': 1, 'day': 3, 'good': 2, 'it': 1, 'going': 1, 'today': 2, 'hav': 3, 'a': 5, 'nic': 1, 'see': 1, 'lat': 1, 'night': 1, 'talk': 1, 'to': 1, 'soon': 1, 'mak': 2, 'me': 1, 'sandwich': 3, 'can': 1, 'what': 1, 'for': 1, 'lunch': 1} /n\n",
      "Clases de palabras: {'sandwich': ['mak', 'me', 'a', 'sandwich', 'can', 'you', 'mak', 'a', 'sandwich', 'hav', 'a', 'sandwich', 'today', 'what', 'for', 'lunch'], 'saludo': ['how', 'ar', 'you', 'how', 'is', 'yo', 'day', 'good', 'day', 'how', 'is', 'it', 'going', 'today'], 'despedida': ['hav', 'a', 'nic', 'day', 'see', 'you', 'lat', 'hav', 'a', 'good', 'night', 'talk', 'to', 'you', 'soon']}\n"
     ]
    }
   ],
   "source": [
    "# se queda con palabras trozadas únicas en el cjto de entrenamiento\n",
    "# CORPUS es una palabra de NLP, se refiere al conjunto total de palabras\n",
    "corpus_palabras = {}  # diccionario que cuenta cuántas palabras trozadas hay\n",
    "clase_palabras = {}  # diccionario donde se agregan las palabras según la clase\n",
    "# convierte la lista en conjunto (set de ítems únicos) y luego a lista otra vez\n",
    "clases = list(set([a['clase'] for a in training_data]))\n",
    "for c in clases:\n",
    "    # prepara una lista de palabras dentro de cada clase\n",
    "    clase_palabras[c] = []\n",
    "\n",
    "# itera dentro de cada oración en el cjto de entrenamiento\n",
    "for data in training_data:\n",
    "    # tokeniza cada oración en palabras como cadenas\n",
    "    for palabra in nltk.word_tokenize(data['oración']):\n",
    "        # ignora algunas cosas\n",
    "        if palabra not in [\"?\", \"'s\"]:\n",
    "            # trocea y pone en minúsculas cada palabra\n",
    "            stemmed_palabra = stemmer.stem(palabra.lower())\n",
    "            # vimos esta palabra antes?\n",
    "            if stemmed_palabra not in corpus_palabras:\n",
    "                corpus_palabras[stemmed_palabra] = 1\n",
    "            else:\n",
    "                corpus_palabras[stemmed_palabra] += 1\n",
    "\n",
    "            # agrega la palabra a nuestras palabras en la lista de clases\n",
    "            clase_palabras[data['clase']].extend([stemmed_palabra])\n",
    "\n",
    "# ahora sabemos cuántas palabras trozadas hay y cuántas veces aparecen\n",
    "print (f\"Corpus de palabras y cantidad: {corpus_palabras} /n\" )\n",
    "# también sabemos cuántas clases de palabras hay y cuáles son ellas\n",
    "print (f\"Clases de palabras: {clase_palabras}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-dKUTuZIdfAt"
   },
   "outputs": [],
   "source": [
    "# Ahora hay que 'codear'el algoritmo\n",
    "\n",
    "# Primera aproximación: suponemos que todas las palabras de la oracion tienen\n",
    "# el mismo 'peso' en la clasificación (no importa si son más o menos comunes)\n",
    "\n",
    "# calcula el score para una clase dada\n",
    "def calcula_score_clase(oracion, clase, show_details=True):\n",
    "    score = 0\n",
    "    # tokeniza cada palabra de la nueva oración\n",
    "    for palabra in nltk.word_tokenize(oracion):\n",
    "        # mira si el stem de la palabra está en alguna de nuestras clases\n",
    "        if stemmer.stem(palabra.lower()) in clase_palabras[clase]:\n",
    "            # asigna a cada palabra el mismo peso\n",
    "            score += 1\n",
    "\n",
    "            if show_details:\n",
    "                print (f\"   encontré: {stemmer.stem(palabra.lower() )}\")\n",
    "    return score\n",
    "\n",
    "# la oración fue tokenizada y las palabras fueron trozadas y pasadas a minúsculas\n",
    "# como los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_FMp13ijdivz",
    "outputId": "7e037aa6-8856-4a5d-f8bc-da83d7c6c816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   encontré: for\n",
      "   encontré: hav\n",
      "   encontré: lunch\n",
      "Clase: sandwich  Score: 3\n",
      "   encontré: good\n",
      "   encontré: day\n",
      "Clase: saludo  Score: 2\n",
      "   encontré: good\n",
      "   encontré: day\n",
      "   encontré: to\n",
      "   encontré: hav\n",
      "Clase: despedida  Score: 4\n"
     ]
    }
   ],
   "source": [
    "# podemos calcular el score para una oración nueva\n",
    "oracion = \"good day for us to have lunch?\"\n",
    "\n",
    "for c in clase_palabras.keys():\n",
    "    print (f\"Clase: {c}  Score: {calcula_score_clase(oracion, c)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EnZ6VccIdmE_"
   },
   "outputs": [],
   "source": [
    "# 2da Aproximación: hay palabras que aparecen con más frecuencia en las\n",
    "# oraciones, o sea, son más 'comunes'. Podemos pensar que por aparecer más\n",
    "# veces podrían 'confundir' al clasificador para asignar la clase a la oración\n",
    "\n",
    "# calcula el score para una dada clase tomando en cuenta qué tan 'comunes' son\n",
    "# las palabras, es decir, cuántas veces aparecen\n",
    "def calcula_score_clase_comun(oracion, clase, show_details=True):\n",
    "    score = 0\n",
    "    # tokeniza la oración en palabras separadas\n",
    "    for palabra in nltk.word_tokenize(oracion):\n",
    "        # mira si la raíz de la palabra está en alguna de nuestra clases\n",
    "        if stemmer.stem(palabra.lower()) in clase_palabras[clase]:\n",
    "            # trata a cada palabra con su peso relativo\n",
    "            score += (1 / corpus_palabras[stemmer.stem(palabra.lower())])\n",
    "\n",
    "            if show_details:\n",
    "                print (f\"   encontré: {stemmer.stem(palabra.lower())} {1 / corpus_palabras[stemmer.stem(palabra.lower())]}\")\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DECw1b7YdpM6",
    "outputId": "2c7821a2-cd20-455e-d08a-01620aadc96a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   encontré: for 1.0\n",
      "   encontré: hav 0.3333333333333333\n",
      "   encontré: lunch 1.0\n",
      "Clase: sandwich  Score: 2.333333333333333\n",
      "   encontré: good 0.5\n",
      "   encontré: day 0.3333333333333333\n",
      "Clase: saludo  Score: 0.8333333333333333\n",
      "   encontré: good 0.5\n",
      "   encontré: day 0.3333333333333333\n",
      "   encontré: to 1.0\n",
      "   encontré: hav 0.3333333333333333\n",
      "Clase: despedida  Score: 2.1666666666666665\n"
     ]
    }
   ],
   "source": [
    "# ahora podemos ver qué pasa con la oración anterior\n",
    "\n",
    "for c in clase_palabras.keys():\n",
    "    print (f\"Clase: {c}  Score: {calcula_score_clase_comun(oracion, c)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gKwiNjdkdsVB"
   },
   "outputs": [],
   "source": [
    "# 3ra Aproximación (y última): buscar la clase con más score y asignarle la oración\n",
    "\n",
    "def clasificar(oracion):\n",
    "    clase_mas_alta = None\n",
    "    score_mas_alto = 0\n",
    "    # iteramos entre las clases\n",
    "    for c in clase_palabras.keys():\n",
    "        # calcula score de la oracion para cada clase\n",
    "        score = calcula_score_clase_comun(oracion, c, show_details=False)\n",
    "        # mira cuál es el score más alto\n",
    "        if score > score_mas_alto:\n",
    "            clase_mas_alta = c\n",
    "            score_mas_alto = score\n",
    "\n",
    "    return clase_mas_alta, score_mas_alto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qxcknuTkdvWd",
    "outputId": "dc67662f-cdca-48ef-9e89-6130a0639627"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sandwich', 2.333333333333333)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasificar(oracion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R4icuHqDdzQD",
    "outputId": "601f0b5d-ce33-470e-8d61-ff5571eed7bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sandwich', 2.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasificar(\"make me some lunch?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QIlX6TVFd2PP",
    "outputId": "5256438b-6c36-46ff-fba0-a4551de93d1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sandwich', 2.033333333333333)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasificar(\"sudo make me a sandwich\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWye_tlzd5CF",
    "outputId": "3c431ba4-eaa5-4e3e-a6a2-79473276fd46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('saludo', 2.083333333333333)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasificar(\"how are you doing today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yexh9gZod7Yv",
    "outputId": "245aacac-6ef9-4569-c0fe-8f5acd4cfc84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('despedida', 2.25)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasificar(\"talk to you tomorrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02ClpHfheAk0",
    "outputId": "2b1de198-f389-439d-8f93-ef6879ce8433"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('saludo', 1.25)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasificar(\"who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fSSJvZqKeDUH",
    "outputId": "74e6faa9-eccc-43cd-ee8d-53f692ceccd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clasificar(\"am I crazy?\")\n",
    "\n",
    "# Bayes Ingenuo? puede ser pero FUNCIONA!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OH2jZZ0518iX",
    "outputId": "bf274149-5e74-4c82-a1c7-098ff548ced5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sandwich', 0.5333333333333333)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasificar('I have a cat')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
